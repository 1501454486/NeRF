task: "kilonerf_replication"
gpus: [1] # set gpu device number
exp_name: "kilonerf"
scene: "lego"

# kilonerf still use nerf's dataset
train_dataset_module: src.datasets.kilonerf.blender
test_dataset_module: src.datasets.kilonerf.blender
dist_dataset_module: src.datasets.kilonerf.blender
network_module: src.models.kilonerf.network
renderer_module: src.models.kilonerf.renderer.volumn_renderer
loss_module: src.train.trainers.kilonerf
evaluator_module: src.evaluators.kilonerf

# teacher model
teacher_model_module: src.models.nerf.network

teacher:
  task: "nerf_replication"
  scene: "lego"
  exp_name: "nerf"


write_video: True

task_arg:  
  N_rays: 1024 # number of rays in each batch
  chunk_size: 32768 # number of points processed in parallel
  renderer_chunk_size: 128  # number of points in each ray, during rendering
  white_bkgd: 1 # use white background
  N_samples: 64 # number of samples per ray in coarse network
  N_importance: 128 # number of samples per ray in fine network
  no_batching: True # True for synthetic datasets
  use_viewdirs: True # whether use full 5D input instead of 3D
  lindisp: False
  perturb: 1
  raw_noise_std: 0
  use_pe: True # whether use positional encoding
  test_skip: 1 # will load 1/N images from test/val sets, useful for large datasets
  precrop_iters: 500
  precrop_frac: 0.5

  # minimum and maximum bounds for this AABB
  aabb: 
    min: [-1.0, -1.0, -1.0]
    max: [1.0, 1.0, 1.0]

  # resolution: (rx, ry, rz)
  grid_resolution: [16, 16, 16] # resolution of the voxel grid
  # apply  l2 regularization to weights and biases of the last 2 layers of the network
  l2_reg: 1e-6
  # epochs of distillation


sampler:
  # an occupancy_factor of 16 results: occ_grid_resolution: [256, 256, 256]
  occ_factor: 16
  # occupancy threshold, a cell is marked occupied if any of the evaluated densities is above this threshold
  occ_threshold: 10
  # Early Ray Termination threshold eps
  ert_threshold: 0.01
  # the maximum number of sampled points
  max_points: 192
  near: 2
  far: 6
  # render step siez for nerfacc
  render_step_size: 0.005


network:
  # arguments for nerf as teacher model
  nerf:
    W: 256 # width of network
    D: 8 # depth of network
    V_D: 1 # appearance depth
    skips: [4]
  xyz_encoder: # encoder for location
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 10 # dimensions of encoding location
  dir_encoder: # encoder for direction
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 4 # dimensions of encoding direction
  # arguments for kilonerf
  kilonerf:
    W: 32 # width of network
    D: 2 # depth of network
  xyz_encoder: # encoder for location
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 10 # dimensions of encoding location
  dir_encoder: # encoder for direction
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 4 # dimensions of encoding direction

train_dataset:
  data_root: "data/lego"
  split: "train"
  input_ratio: 1. # whether to downsampling the image, you can set it to 0.5 to acclerate training
  cams: [0, -1, 1] # input cameras, you can use this variable to select training images
  H: 800
  W: 800

val_dataset:
  data_root: "data/lego"
  split: "val"
  input_ratio: 0.5
  cams: [0, -1, 50]
  H: 800
  W: 800

test_dataset:
  data_root: "data/lego"
  split: "test"
  input_ratio: 1
  cams: [0, -1,1]
  H: 800
  W: 800

dist_dataset:
  data_root: "data/lego/distilled"
  split: "train"

train:
  single_view: False
  batch_size: 4
  lr: 5e-4 # learning rate
  weight_decay: 0.
  ep_dist: 300      # 150k iters for distillation
  ep_ft: 2000       # 1000k iters for fine-tuning
  epoch: 2300
  optim: 'adam'
  scheduler:
    distillation:
      type: "exponential"
      gamma: 0.9
      decay_epochs: 100
    fine_tuning:
      type: "exponential"
      gamma: 0.1
      decay_epochs: 500
  num_workers: 12

test:
  batch_size: 1
  # model to be tested
  model_name: kilonerf

eval:
  whole_img: True

ep_iter: 500 # number of iterations in each epoch
save_ep: 40
eval_ep: 40 # 20000 iterations
save_latest_ep: 10 # 5000 iterations
log_interval: 250
